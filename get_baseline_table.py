# -*- coding: utf-8 -*-
import sys
import os
sys.path.append("src") # ç¡®ä¿èƒ½æ‰¾åˆ° dataset.py
import torch
import numpy as np
import json
from tqdm import tqdm
from torch.utils.data import DataLoader

# å¼•å…¥è®¡ç®—åº“
try:
    from thop import profile
except ImportError:
    print("âŒ é”™è¯¯: è¯·å…ˆå®‰è£… thop åº“: pip install thop")
    sys.exit(1)

from monai.metrics import (
    compute_dice, 
    compute_hausdorff_distance, 
    compute_average_surface_distance,
    compute_iou
)
from monai.networks.nets import UNet, SwinUNETR
from dataset import TearDataset
from monai.networks.nets import UNet, SwinUNETR, AttentionUnet, SegResNet

# é…ç½®
IMG_SIZE = 1024
# æ¨ç†æ—¶ä½¿ç”¨ GPUï¼Œä½†è®¡ç®— FLOPs æ—¶å»ºè®®ç”¨ CPU é˜²æ­¢çˆ†æ˜¾å­˜
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def get_model(name):
    if name == "unet":
        return UNet(
            spatial_dims=2, in_channels=3, out_channels=1,
            channels=(32, 64, 128, 256, 512),
            strides=(2, 2, 2, 2), num_res_units=2,
        )
    elif name == "swinunet":
        return SwinUNETR(
            in_channels=3, out_channels=1,
            feature_size=24, spatial_dims=2,
            use_v2=True,       # å»ºè®®å¼€å¯ SwinV2ï¼Œæ›´ç¨³
            window_size=8      # ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘æ”¹æˆ 8 å®Œç¾é€‚é… 1024 åˆ†è¾¨ç‡
        )
    # === æ–°å¢æ¨¡å‹ 1: Attention U-Net ===
    elif name == "attentionunet":
        return AttentionUnet(
            spatial_dims=2, in_channels=3, out_channels=1,
            channels=(32, 64, 128, 256, 512),
            strides=(2, 2, 2, 2),
        )
    # === æ–°å¢æ¨¡å‹ 2: SegResNet (NVIDIAå¼ºåŠ›æ¨¡å‹) ===
    elif name == "segresnet":
        return SegResNet(
            spatial_dims=2, in_channels=3, out_channels=1,
            init_filters=32, blocks_down=[1, 2, 2, 4], blocks_up=[1, 1, 1]
        )
    else:
        raise ValueError(f"Unknown model: {name}")

def get_complexity(model_name):
    """è®¡ç®—å‚æ•°é‡å’Œ FLOPs (å¼ºåˆ¶ä½¿ç”¨ CPU ä»¥å… 1024x1024 çˆ†æ˜¾å­˜)"""
    print(f"â³ æ­£åœ¨è®¡ç®— {model_name} çš„å¤æ‚åº¦ (CPUæ¨¡å¼)...")
    model = get_model(model_name).to("cpu") # å¼ºåˆ¶ CPU
    model.eval()
    
    # åˆ›å»ºä¸€ä¸ª dummy è¾“å…¥ (1, 3, 1024, 1024)
    input_tensor = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to("cpu")
    
    # è®¡ç®— FLOPs å’Œ Params
    try:
        flops, params = profile(model, inputs=(input_tensor, ), verbose=False)
    except Exception as e:
        print(f"âš ï¸ FLOPs è®¡ç®—å‡ºé”™: {e}")
        return 0, 0
    
    # è½¬æ¢ä¸º G (Giga) å’Œ M (Million)
    flops_g = flops / 1e9
    params_m = params / 1e6
    
    return flops_g, params_m

def calculate_metrics(pred, lbl):
    results = {}
    results['dice'] = compute_dice(pred, lbl, include_background=False).item()
    results['iou'] = compute_iou(pred, lbl, include_background=False).item()
    
    tp = (pred * lbl).sum().item()
    fp = (pred * (1 - lbl)).sum().item()
    fn = ((1 - pred) * lbl).sum().item()
    
    results['recall'] = tp / (tp + fn + 1e-6)
    results['precision'] = tp / (tp + fp + 1e-6)
    
    if lbl.sum() > 0 and pred.sum() > 0:
        results['hd95'] = compute_hausdorff_distance(pred, lbl, include_background=False, percentile=95).item()
        results['asd'] = compute_average_surface_distance(pred, lbl, include_background=False).item()
    elif lbl.sum() > 0:
        results['hd95'] = 100.0; results['asd'] = 50.0
    else:
        results['hd95'] = 0.0; results['asd'] = 0.0
    return results

def evaluate_fold(model_name, fold):
    split_path = f"./data_splits/fold_{fold}.json"
    # å…¼å®¹æ€§æ£€æŸ¥ï¼šå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨
    if not os.path.exists(split_path):
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ•°æ®åˆ‡åˆ†æ–‡ä»¶: {split_path}")
        return None

    with open(split_path, 'r') as f: data = json.load(f)
    
    dataset = TearDataset(data['val'], mode='val', img_size=IMG_SIZE)
    # éªŒè¯é›† batch_size=1 æ˜¯æœ€å®‰å…¨çš„
    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4)
    
    model = get_model(model_name).to(DEVICE)
    ckpt_path = f"./checkpoints_baseline/{model_name}/fold_{fold}/best_model.pth"
    
    if not os.path.exists(ckpt_path):
        print(f"âš ï¸ [Fold {fold}] æ²¡æ‰¾åˆ°æƒé‡: {ckpt_path}")
        return None

    # --- ä¿®æ­£åçš„ç¨³å¥åŠ è½½é€»è¾‘ ---
    state_dict = torch.load(ckpt_path, map_location=DEVICE)
    new_state_dict = {}
    for k, v in state_dict.items():
        # ç§»é™¤ 'module.' å‰ç¼€ (é’ˆå¯¹ DataParallel ä¿å­˜çš„æ¨¡å‹)
        if k.startswith("module."):
            new_state_dict[k[7:]] = v
        else:
            new_state_dict[k] = v
            
    # strict=True èƒ½å¸®ä½ æ£€æŸ¥æƒé‡æ˜¯å¦çœŸçš„åŒ¹é…ï¼Œå¦‚æœæœ‰ key ä¸åŒ¹é…ä¼šç›´æ¥æŠ¥é”™æé†’ä½ 
    # å¦‚æœä½ ç¡®å®šæœ‰äº›å±‚ä¸éœ€è¦åŠ è½½ï¼Œå¯ä»¥æ”¹å› strict=False
    try:
        model.load_state_dict(new_state_dict, strict=True)
    except Exception as e:
        print(f"âš ï¸ æƒé‡åŠ è½½æœ‰è½»å¾®ä¸åŒ¹é…ï¼Œå°è¯• strict=False åŠ è½½... ({e})")
        model.load_state_dict(new_state_dict, strict=False)
        
    model.eval()
    
    metrics_log = {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []}
    
    with torch.no_grad():
        for batch in tqdm(loader, leave=False, desc=f"Fold {fold}"):
            img, lbl = batch['image'].to(DEVICE), batch['label'].to(DEVICE)
            logits = model(img)
            pred = (torch.sigmoid(logits) > 0.5).float()
            pred, lbl = pred.cpu(), lbl.cpu()
            batch_res = calculate_metrics(pred, lbl)
            for k, v in batch_res.items(): metrics_log[k].append(v)
                
    return {k: np.mean(v) for k, v in metrics_log.items()}

def main():
    print("ğŸš€ å¼€å§‹ Baseline ç»Ÿè®¡ (å« Params & FLOPs)...")
    
    for model_name in ["attentionunet"]:
        print(f"\n{'='*90}")
        print(f"ğŸ“‹ Model: {model_name.upper()}")
        
        # 1. è®¡ç®—å¤æ‚åº¦ (CPU)
        flops, params = get_complexity(model_name)
        print(f"ğŸ” Complexity: Params = {params:.2f} M | FLOPs = {flops:.2f} G")

        # 2. æ‰“å°è¡¨å¤´
        headers = ["Fold", "Dice", "IoU", "Recall", "Prec", "HD95", "ASD"]
        header_str = " | ".join([f"{h:<8}" for h in headers])
        print("-" * 90)
        print(header_str)
        print("-" * 90)
        
        all_folds_metrics = {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []}
        
        for fold in range(5):
            res = evaluate_fold(model_name, fold)
            if res is not None:
                for k, v in res.items(): all_folds_metrics[k].append(v)
                row_str = f"{fold:<8} | {res['dice']:.4f}   | {res['iou']:.4f}   | {res['recall']:.4f}   | {res['precision']:.4f} | {res['hd95']:.4f}   | {res['asd']:.4f}"
                print(row_str)
        
        if len(all_folds_metrics['dice']) > 0:
            print("-" * 90)
            print(f"ğŸ† {model_name.upper()} Final Average:")
            for k in headers[1:]:
                k_lower = k.lower() if k != "Prec" else "precision"
                avg = np.mean(all_folds_metrics[k_lower])
                std = np.std(all_folds_metrics[k_lower])
                print(f"   {k:<8}: {avg:.4f} Â± {std:.4f}")
            print(f"   Params  : {params:.2f} M")
            print(f"   FLOPs   : {flops:.2f} G")
        else:
            print("âŒ æœªèƒ½ç”Ÿæˆä»»ä½•æœ‰æ•ˆæ•°æ® (å¯èƒ½æ˜¯ Checkpoint è·¯å¾„ä¸å¯¹)")

if __name__ == "__main__":
    main()