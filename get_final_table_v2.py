import sys
import os
import argparse
sys.path.append("src") # ç¡®ä¿èƒ½æ‰¾åˆ° dataset å’Œ model

import torch
import numpy as np
import json
import math
from tqdm import tqdm
from torch.utils.data import DataLoader

# å°è¯•å¯¼å…¥ thopï¼Œæ²¡æœ‰ä¹Ÿä¸è¦ç´§ï¼Œåªå½±å“ FLOPs
try:
    from thop import profile
    THOP_AVAILABLE = True
except ImportError:
    THOP_AVAILABLE = False
    print("âš ï¸ æœªæ£€æµ‹åˆ° thopï¼Œå°†è·³è¿‡ FLOPs è®¡ç®— (pip install thop)")

# å¯¼å…¥ MONAI æŒ‡æ ‡
try:
    from monai.metrics import (
        compute_dice, compute_hausdorff_distance, 
        compute_average_surface_distance, compute_iou
    )
except ImportError:
    print("âŒ å¿…é¡»å®‰è£… monai: pip install monai")
    sys.exit(1)

from dataset import TearDataset
from model import ST_SAM

# ================= é…ç½®åŒºåŸŸ =================
IMG_SIZE = 1024
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# HD95 çš„æœ€å¤§æƒ©ç½šå€¼ï¼šè®¾ä¸ºå›¾åƒå¯¹è§’çº¿é•¿åº¦ (æ›´ç§‘å­¦)
MAX_HD95 = np.sqrt(IMG_SIZE**2 + IMG_SIZE**2) 
# ===========================================

def get_model_complexity(model):
    """
    ç²¾ç¡®è®¡ç®— Params (Total & Tunable) å’Œ FLOPs
    """
    # 1. è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    tunable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    # 2. è®¡ç®— FLOPs (ä½¿ç”¨ dummy input)
    flops_g = 0.0
    if THOP_AVAILABLE:
        try:
            model.eval()
            # æ„é€  dummy input: å›¾åƒ [1, 3, 1024, 1024] + Box [1, 4]
            input_img = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)
            input_box = torch.tensor([[0, 0, IMG_SIZE, IMG_SIZE]]).float().to(DEVICE)
            
            # thop å¯èƒ½ä¼šå› ä¸º SAM2 å†…éƒ¨ç»“æ„å¤æ‚è€ŒæŠ¥è­¦ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            flops, _ = profile(model, inputs=(input_img, input_box), verbose=False)
            flops_g = flops / 1e9
        except Exception as e:
            print(f"âš ï¸ FLOPs calculation failed: {e}")
    
    return total_params / 1e6, tunable_params / 1e6, flops_g

def calculate_metrics_robust(pred, lbl):
    """
    è®¡ç®—å•å¼ å›¾åƒçš„æŒ‡æ ‡ï¼Œå¤„ç†è¾¹ç¼˜æƒ…å†µ
    pred: [1, 1, H, W] (0 or 1)
    lbl:  [1, 1, H, W] (0 or 1)
    """
    results = {}
    
    # 1. Dice & IoU (MONAI)
    # include_background=False è¡¨ç¤ºåªè®¡ç®—å‰æ™¯ç±»
    dice_score = compute_dice(pred, lbl, include_background=False).item()
    iou_score = compute_iou(pred, lbl, include_background=False).item()
    
    # ç‰¹æ®Šæƒ…å†µä¿®æ­£ï¼šå¦‚æœæ ‡ç­¾ä¸ºç©ºï¼Œé¢„æµ‹ä¹Ÿä¸ºç©ºï¼ŒDice ç†è®ºä¸Šåº”ä¸º 1.0 (å®Œå…¨æ­£ç¡®)
    # ä½† compute_dice é»˜è®¤å¯èƒ½ç»™ 0ã€‚è¿™é‡Œæ ¹æ®åŒ»å­¦åˆ†å‰²æƒ¯ä¾‹ä¿®æ­£ï¼š
    if lbl.sum() == 0 and pred.sum() == 0:
        dice_score = 1.0
        iou_score = 1.0
    
    results['dice'] = dice_score
    results['iou'] = iou_score
    
    # 2. Precision & Recall (æ‰‹ç®—æ›´ç¨³)
    tp = (pred * lbl).sum().item()
    fp = (pred * (1 - lbl)).sum().item()
    fn = ((1 - pred) * lbl).sum().item()
    
    results['recall'] = tp / (tp + fn + 1e-6)
    results['precision'] = tp / (tp + fp + 1e-6)
    
    # 3. HD95 & ASD (è·ç¦»æŒ‡æ ‡)
    # åªæœ‰å½“ Pred å’Œ GT éƒ½æœ‰å‰æ™¯æ—¶ï¼Œè·ç¦»æ‰æœ‰æ„ä¹‰
    if lbl.sum() > 0 and pred.sum() > 0:
        results['hd95'] = compute_hausdorff_distance(pred, lbl, include_background=False, percentile=95).item()
        results['asd'] = compute_average_surface_distance(pred, lbl, include_background=False).item()
    elif lbl.sum() > 0 and pred.sum() == 0:
        # æ¼æ£€ï¼šæƒ©ç½šä¸ºæœ€å¤§è·ç¦»
        results['hd95'] = MAX_HD95 
        results['asd'] = MAX_HD95 / 2 # ç»éªŒå€¼ï¼Œæˆ–è€…ä¹Ÿè®¾ä¸º MAX
    else:
        # GT ä¸ºç©º (æ— ç—…ç¶)ï¼š
        # å¦‚æœé¢„æµ‹ä¹Ÿæ˜¯ç©ºï¼Œè·ç¦»ä¸º0ï¼›å¦‚æœé¢„æµ‹æœ‰ä¸œè¥¿ï¼Œåˆ™è·ç¦»å¾ˆå¤§
        if pred.sum() == 0:
            results['hd95'] = 0.0
            results['asd'] = 0.0
        else:
            results['hd95'] = MAX_HD95
            results['asd'] = MAX_HD95

    return results

def evaluate_fold(fold):
    print(f"ğŸ”„ Evaluating Fold {fold} ...")
    split_path = f"./data_splits/fold_{fold}.json"
    ckpt_path = f"./checkpoints/fold_{fold}/best_model.pth"
    
    if not os.path.exists(ckpt_path):
        print(f"âš ï¸ Checkpoint not found: {ckpt_path}, skipping Fold {fold}")
        return None
    
    # åŠ è½½æ•°æ®
    with open(split_path, 'r') as f: data = json.load(f)
    
    # ğŸ”¥ã€ä¿®æ”¹è¿™é‡Œã€‘ï¼šæŠŠ YOLO çš„ JSON è·¯å¾„ä¼ è¿›å»ï¼
    yolo_json_path = f"./data_splits/yolo_boxes_fold{fold}.json"
    dataset = TearDataset(data['val'], mode='val', img_size=IMG_SIZE, yolo_pred_json=yolo_json_path)
    
    # éªŒè¯é›† BatchSize å¿…é¡»ä¸º 1 ä»¥ä¿è¯ Metric è®¡ç®—å‡†ç¡®
    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)
    
    # åŠ è½½æ¨¡å‹
    model = ST_SAM(checkpoint_path="./checkpoints/sam2_hiera_large.pt").to(DEVICE)
    
    # åŠ è½½æƒé‡ (å¤„ç† DDP å‰ç¼€)
    state_dict = torch.load(ckpt_path, map_location=DEVICE)
    new_state_dict = {}
    for k, v in state_dict.items():
        name = k.replace("module.", "") # å»æ‰ DDP äº§ç”Ÿçš„ module. å‰ç¼€
        new_state_dict[name] = v
    model.load_state_dict(new_state_dict)
    model.eval()
    
    fold_metrics = {
        'Colour': {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []},
        'Infrared': {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []}
    }

    with torch.no_grad():
        for batch in tqdm(loader, leave=False, desc=f"Fold {fold}"):
            img = batch['image'].to(DEVICE)
            lbl = batch['label'].to(DEVICE)
            box = batch['box'].to(DEVICE)

            img_id = str(batch['id'][0]).lower()
            if 'colour' in img_id or 'color' in img_id:
                modality = 'Colour'
            else:
                modality = 'Infrared'

            logits = model(img, box)
            pred = (torch.sigmoid(logits) > 0.5).float()

            batch_res = calculate_metrics_robust(pred.cpu(), lbl.cpu())
            for k, v in batch_res.items():
                fold_metrics[modality][k].append(v)

    res_summary = {}
    for mod in ['Colour', 'Infrared']:
        if len(fold_metrics[mod]['dice']) > 0:
            res_summary[mod] = {k: np.mean(v) for k, v in fold_metrics[mod].items()}
    return res_summary

if __name__ == "__main__":
    print(f"\nğŸš€ ST-SAM æœ€ç»ˆè¯„ä¼°è„šæœ¬ (SCI Mode)")
    print(f"ğŸ“Œ Device: {DEVICE} | Image Size: {IMG_SIZE}")
    print("-" * 100)
    
    # 1. è®¡ç®—å¤æ‚åº¦ (åªç®—ä¸€æ¬¡)
    print("ğŸ”¹ Calculating Complexity...")
    try:
        # åˆå§‹åŒ–ä¸€ä¸ªä¸´æ—¶æ¨¡å‹ç”¨äºè®¡ç®—å‚æ•°
        temp_model = ST_SAM(checkpoint_path="./checkpoints/sam2_hiera_large.pt").to(DEVICE)
        total_p, tunable_p, flops = get_model_complexity(temp_model)
        del temp_model # é‡Šæ”¾æ˜¾å­˜
        torch.cuda.empty_cache()
    except Exception as e:
        print(f"âš ï¸ Complexity Error: {e}")
        total_p, tunable_p, flops = 0, 0, 0

    # 2. å¾ªç¯è¯„ä¼° 5 Folds
    headers = ["Fold", "Dice", "IoU", "Recall", "Prec", "HD95", "ASD"]
    global_metrics = {
        'Colour':   {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []},
        'Infrared': {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []},
        'Overall':  {'dice': [], 'iou': [], 'recall': [], 'precision': [], 'hd95': [], 'asd': []}
    }

    for fold in [0, 1, 2, 3, 4]:
        res_summary = evaluate_fold(fold)
        if not res_summary:
            continue

        print(f"Fold {fold} Results:")
        for mod, metrics in res_summary.items():
            row = [
                f"{mod[:4]:<8}",
                f"{metrics['dice']:.4f}", f"{metrics['iou']:.4f}",
                f"{metrics['recall']:.4f}", f"{metrics['precision']:.4f}",
                f"{metrics['hd95']:.2f}", f"{metrics['asd']:.2f}"
            ]
            print(" | ".join(row))
            for k, v in metrics.items():
                global_metrics[mod][k].append(v)
                global_metrics['Overall'][k].append(v)

    # 3. è¾“å‡ºæœ€ç»ˆæ±‡æ€» (Mean Â± Std)
    if len(global_metrics['Overall']['dice']) > 0:
        print("-" * 100)
        print("ğŸ† ST-SAM Modality-Aware Final Results:")
        print("-" * 100)

        for category in ['Colour', 'Infrared', 'Overall']:
            if len(global_metrics[category]['dice']) == 0:
                continue
            print(f"\n--- {category} Set ---")
            for k in headers[1:]:
                key = k.lower() if k != "Prec" else "precision"
                vals = global_metrics[category][key]
                print(f"  â— {k:<10}: {np.mean(vals):.4f} Â± {np.std(vals):.4f}")

        print("-" * 100)
        print("ğŸ“‰ Model Efficiency (Paper Claims):")
        print(f"  â— Total Params   : {total_p:.2f} M")
        print(f"  â— Tunable Params : {tunable_p:.2f} M  <-- (é‡ç‚¹: PEFT)")
        print(f"  â— GFLOPs         : {flops:.2f} G")
        print("=" * 100)
    else:
        print("âŒ No results generated. Check checkpoints.")