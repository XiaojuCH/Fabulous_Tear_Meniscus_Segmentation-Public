import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
import sys

# ç¡®ä¿èƒ½å¯¼å…¥ä½ çš„æ¨¡å‹
sys.path.append(".") 
from model import ST_SAM

# =================é…ç½®åŒºåŸŸ=================
# æ‰¾ä¸€å¼ å…¸å‹çš„çº¢å¤–å›¾ (æ¯”å¦‚æœ‰åŒå¿ƒåœ†å¹²æ‰°çš„)
IMG_PATH = r"/workspace/data/root/xiaoju/Unet/dataset/Infrared3/Original/Infrared3_000012.PNG" 
# æˆ–è€…æ˜¯å½©å›¾
# IMG_PATH = "data/root/xiaoju/Eye_River_new/Color1_000000.jpg"

CHECKPOINT = "./checkpoints/sam2_hiera_large.pt" # ä½ çš„ SAM2 æƒé‡
ST_SAM_CKPT = "./checkpoints/fold_0/best_model.pth" # ä½ çš„ ST-SAM è®­ç»ƒæƒé‡
device = "cuda" if torch.cuda.is_available() else "cpu"
# =========================================

def visualize():
    # 1. åŠ è½½æ¨¡å‹
    print("â³ Loading model...")
    model = ST_SAM(checkpoint_path=CHECKPOINT).to(device)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡ (å¤„ç† DDP çš„ module. å‰ç¼€)
    state_dict = torch.load(ST_SAM_CKPT, map_location=device)
    new_state = {k.replace("module.", ""): v for k, v in state_dict.items()}
    model.load_state_dict(new_state)
    model.eval()

    # 2. è¯»å–å¹¶é¢„å¤„ç†å›¾ç‰‡
    if not os.path.exists(IMG_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°å›¾ç‰‡: {IMG_PATH}")
        return

    img_bgr = cv2.imread(IMG_PATH)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    original_h, original_w = img_rgb.shape[:2]

    # SAM éœ€è¦ 1024x1024
    input_img = cv2.resize(img_rgb, (1024, 1024))
    img_tensor = torch.from_numpy(input_img).permute(2, 0, 1).float() / 255.0
    img_tensor = img_tensor.unsqueeze(0).to(device) # [1, 3, 1024, 1024]
    
    # æ„é€ å…¨å›¾ Box Prompt
    box = torch.tensor([[0, 0, 1024, 1024]], device=device).float()

    # 3. æ¨ç† (è§¦å‘ forward é’©å­ä¿å­˜æƒé‡)
    print("ğŸš€ Running inference...")
    with torch.no_grad():
        _ = model(img_tensor, box)

    # 4. æå–æƒé‡
    # ä½ çš„æ¨¡å‹é‡Œæœ‰ adapter_s0 (é«˜åˆ†) å’Œ adapter_s1 (ä½åˆ†)
    # æˆ‘ä»¬çœ‹ adapter_s1 (128x128) æ¯”è¾ƒç›´è§‚ï¼Œå› ä¸ºå®ƒè´Ÿè´£æ•´ä½“æŠ—å¹²æ‰°
    try:
        # [1, 6, C, H, W] -> mean over Channel -> [6, H, W]
        weights = model.adapter_s1.last_weights.mean(dim=2).squeeze(0).cpu().numpy()
    except AttributeError:
        print("âŒ æå–å¤±è´¥ï¼è¯·ç¡®è®¤ä½ æ˜¯å¦åœ¨ NNNew_att_v2_PPPGPT.py é‡ŒåŠ äº† `self.last_weights = ...`")
        return

    # 5. ç»˜å›¾
    branch_names = [
        "Strip-H (Large)", "Strip-W (Large)", 
        "Strip-H (Small)", "Strip-W (Small)", 
        "Local-3x3 (Pupil)", "Local-5x5 (Halo)"
    ]
    
    plt.figure(figsize=(24, 10))
    
    # åŸå›¾
    plt.subplot(2, 4, 1)
    plt.imshow(img_rgb)
    plt.title("Input Image", fontsize=15)
    plt.axis("off")
    
    # ç»˜åˆ¶ 6 ä¸ªåˆ†æ”¯çš„çƒ­åŠ›å›¾
    for i in range(6):
        plt.subplot(2, 4, i+2)
        
        # å°† 128x128 çš„çƒ­åŠ›å›¾æ’å€¼å›åŸå›¾å¤§å°
        heatmap = cv2.resize(weights[i], (original_w, original_h))
        
        # å½’ä¸€åŒ–åˆ° 0-1 ä»¥ä¾¿è§‚å¯Ÿç›¸å¯¹å¼ºå¼±
        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
        
        plt.imshow(heatmap, cmap='jet')
        plt.title(f"{branch_names[i]}\n(Red=Active, Blue=Inactive)", fontsize=12)
        plt.axis("off")
        plt.colorbar(fraction=0.046, pad=0.04)

    save_path = "vis_competition.png"
    plt.savefig(save_path, bbox_inches='tight')
    print(f"âœ… Visualization saved to {save_path}")
    plt.show()

if __name__ == "__main__":
    visualize()