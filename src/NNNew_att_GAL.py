import torch
import torch.nn as nn
import torch.nn.functional as F

# =========================================
# åŸºç¡€ç»„ä»¶ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯å—
# =========================================
class DWConv(nn.Module):
    def __init__(self, dim, kernel_size, padding, dilation=1):
        super().__init__()
        # ä»…åœ¨ç©ºé—´ç»´åº¦è¿›è¡Œå·ç§¯ï¼Œæå¤§åœ°èŠ‚çœå‚æ•°é‡
        self.dw = nn.Conv2d(
            dim, dim, 
            kernel_size=kernel_size, 
            padding=padding, 
            dilation=dilation, 
            groups=dim, 
            bias=False
        )
        self.bn = nn.BatchNorm2d(dim)
        self.act = nn.GELU() # ç»Ÿä¸€ä½¿ç”¨æ›´ç°ä»£çš„ GELU æ¿€æ´»å‡½æ•°

    def forward(self, x):
        return self.act(self.bn(self.dw(x)))

# =========================================
# æ ¸å¿ƒåˆ›æ–°ï¼šå‡ ä½•æ„ŸçŸ¥çº¿æ€§é€‚é…å™¨ (GAL-Adapter)
# =========================================
class GAL_Adapter(nn.Module):
    def __init__(self, in_channels, kernel_size_large=23, kernel_size_small=7, reduction=4):
        """
        in_channels: è¾“å…¥ç‰¹å¾å›¾çš„é€šé“æ•°
        kernel_size_large/small: é•¿æ¡å·ç§¯çš„æ ¸å¤§å°ï¼Œç”¨äºæ•è·æ³ªæ²³ç»†é•¿æ‹“æ‰‘
        reduction: ç“¶é¢ˆå±‚é™ç»´ç³»æ•°ï¼Œç”¨äºæ§åˆ¶è®¡ç®—é‡
        """
        super().__init__()
        self.proj_in = nn.Conv2d(in_channels, in_channels, 1, bias=False)

        # -----------------------------------------
        # æ”¹è¿› 1ï¼šæ‰“é€šç‰¹å¾éš”ç¦»
        # ä½¿ç”¨æ ‡å‡†çš„ 3x3 å·ç§¯ä»£æ›¿ DWConvï¼Œç¡®ä¿ç‰¹å¾åœ¨è¿›å…¥å¤šåˆ†æ”¯å‰ï¼Œ
        # å„ä¸ªé€šé“çš„ä¿¡æ¯èƒ½å¤Ÿå……åˆ†æ··åˆ (Channel Mixing)ï¼Œå¢å¼ºå‡ ä½•å…ˆéªŒçš„è¡¨è¾¾ã€‚
        # -----------------------------------------
        self.pre_orient = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.GELU()
        )

        # --- å„å‘å¼‚æ€§åˆ†æ”¯ (æ•æ‰ç»†é•¿æ³ªæ²³) ---
        pad_l = (kernel_size_large - 1) // 2
        pad_s = (kernel_size_small - 1) // 2
        self.strip_h_large = DWConv(in_channels, (kernel_size_large, 1), (pad_l, 0))
        self.strip_w_large = DWConv(in_channels, (1, kernel_size_large), (0, pad_l))
        self.strip_h_small = DWConv(in_channels, (kernel_size_small, 1), (pad_s, 0))
        self.strip_w_small = DWConv(in_channels, (1, kernel_size_small), (0, pad_s))

        # --- å„å‘åŒæ€§åˆ†æ”¯ (æ•æ‰å±€éƒ¨ç»†èŠ‚ï¼Œæ’é›·åå…‰ç¯ä¼ªå½±) ---
        self.local_3x3 = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.GELU()
        )
        self.local_5x5 = DWConv(in_channels, 3, padding=2, dilation=2)

        # -----------------------------------------
        # æ”¹è¿› 2ï¼šå¼•å…¥ Bottleneck è§£å†³æµ…å±‚ç®—åŠ›é»‘æ´
        # 6ä¸ªåˆ†æ”¯æ‹¼æ¥åç»´åº¦å¾ˆé«˜ï¼Œå¦‚æœåœ¨ s0/s1 å±‚ç›´æ¥åšå¯†é›†å·ç§¯ä¼šå¼•å…¥å·¨å¤§è®¡ç®—é‡ã€‚
        # è¿™é‡Œå…ˆé™ç»´ (mid_channels) å†å‡ç»´ï¼Œæ—¢é™ä½äº† FLOPsï¼Œåˆå¢åŠ äº†éçº¿æ€§ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
        # -----------------------------------------
        mid_channels = max(in_channels * 6 // reduction, 16)
        self.branch_weight = nn.Sequential(
            nn.Conv2d(in_channels * 6, mid_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.GELU(),
            nn.Conv2d(mid_channels, in_channels * 6, kernel_size=1, bias=False)
        )

        # --- è·¨ä¸­å¿ƒé£æ ¼è°ƒåˆ¶æ¨¡å— (CCSM) ---
        self.style_fc = nn.Sequential(
            nn.Conv2d(in_channels * 2, in_channels, 1), # *2 æ˜¯å› ä¸ºè¦æ‹¼æ¥ Mean å’Œ Std
            nn.GELU(),
            nn.Conv2d(in_channels, in_channels * 2, 1)  # è¾“å‡º gamma + beta
        )

        self.proj_out = nn.Conv2d(in_channels, in_channels, 1, bias=False)

    def forward(self, x):
        shortcut = x
        x = self.proj_in(x)

        # 1. è·¨é€šé“å‡ ä½•é¢„å¤„ç†
        x_oriented = self.pre_orient(x)

        # 2. å¤šåˆ†æ”¯ç‰¹å¾æå–
        lh = self.strip_h_large(x_oriented)
        lw = self.strip_w_large(x_oriented)
        sh = self.strip_h_small(x_oriented)
        sw = self.strip_w_small(x_oriented)
        loc3 = self.local_3x3(x)
        loc5 = self.local_5x5(x)

        branches = [lh, lw, sh, sw, loc3, loc5]

        # 3. ç«äº‰æ€§é—¨æ§æœºåˆ¶ (Competitive Gating)
        cat_feat = torch.cat(branches, dim=1)
        weight = self.branch_weight(cat_feat)

        B, C6, H, W = weight.shape
        C = C6 // 6
        weight = weight.view(B, 6, C, H, W)
        weight = F.softmax(weight, dim=1) # åˆ†æ”¯é—´çš„è½¯ç«äº‰

        stacked = torch.stack(branches, dim=1)
        out = (weight * stacked).sum(dim=1) # åŠ¨æ€èåˆç‰¹å¾

        # 4. è·¨ä¸­å¿ƒé£æ ¼è°ƒåˆ¶ (Cross-Center Style Modulation)
        b, c, h, w = out.shape
        out_flat = out.view(b, c, -1)
        
        # æå–å…¨å±€å‡å€¼ (äº®åº¦/åŸºç¡€ä¸Šä¸‹æ–‡)
        feat_mean = out_flat.mean(dim=2, keepdim=True).unsqueeze(-1)
        
        # -----------------------------------------
        # ğŸš¨ è‡´å‘½ Bug ä¿®å¤ï¼šå¼ºåˆ¶è®¾ç½® unbiased=False
        # å¿…é¡»åŠ ä¸Šï¼Œå¦åˆ™å½“éªŒè¯é›†é‡åˆ°æå° YOLO æ¡†å¯¼è‡´ H=1,W=1 æ—¶ï¼Œä¼šå› é™¤ä»¥ 0 å´©æºƒï¼
        # -----------------------------------------
        feat_std = (out_flat.var(dim=2, keepdim=True, unbiased=False) + 1e-5).sqrt().unsqueeze(-1)
        
        # æ‹¼æ¥é£æ ¼ç‰¹å¾
        style_feat = torch.cat([feat_mean, feat_std], dim=1)
        
        gamma_beta = self.style_fc(style_feat)
        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)
        
        # -----------------------------------------
        # æ”¹è¿› 3ï¼šè§£å¼€æ–¹å·®å‹ç¼©å°å°
        # ä½¿ç”¨ 2.0 * Sigmoidï¼Œè®©ç¼©æ”¾ç³»æ•° gamma ä¸­å¿ƒå¯¹é½åˆ° 1.0ã€‚
        # æ—¢èƒ½æ”¾å¤§ä¹Ÿèƒ½ç¼©å°ç‰¹å¾ï¼Œé¿å…æµ…å±‚ç‰¹å¾æ¢¯åº¦æ¶ˆå¤±ã€‚
        # -----------------------------------------
        gamma = 2.0 * torch.sigmoid(gamma) 
        
        # ä»¿å°„å˜æ¢è¿›è¡ŒåŸŸå¯¹é½
        out = gamma * out + beta
        out = self.proj_out(out)

        # å¼•å…¥æ®‹å·®è¿æ¥
        return shortcut + out