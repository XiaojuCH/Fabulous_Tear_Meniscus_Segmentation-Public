import torch
import torch.nn as nn
import torch.nn.functional as F

class DWConv(nn.Module):
    def __init__(self, dim, kernel_size, padding, dilation=1):
        super().__init__()
        self.dw = nn.Conv2d(
            dim, dim, 
            kernel_size=kernel_size, 
            padding=padding, 
            dilation=dilation, 
            groups=dim, 
            bias=False
        )
        self.bn = nn.BatchNorm2d(dim)
        self.act = nn.GELU()

    def forward(self, x):
        return self.act(self.bn(self.dw(x)))

class GAL_Adapter(nn.Module):
    def __init__(self, in_channels, kernel_size_large=23, kernel_size_small=7, reduction=4):
        super().__init__()
        self.proj_in = nn.Conv2d(in_channels, in_channels, 1, bias=False)

        # 1. è·¨é€šé“ç‰¹å¾æ··åˆ
        self.pre_orient = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.GELU()
        )

        # 2. å„å‘å¼‚æ€§åˆ†æ”¯ (æ•è·ç»†é•¿æ³ªæ²³)
        pad_l = (kernel_size_large - 1) // 2
        pad_s = (kernel_size_small - 1) // 2
        self.strip_h_large = DWConv(in_channels, (kernel_size_large, 1), (pad_l, 0))
        self.strip_w_large = DWConv(in_channels, (1, kernel_size_large), (0, pad_l))
        self.strip_h_small = DWConv(in_channels, (kernel_size_small, 1), (pad_s, 0))
        self.strip_w_small = DWConv(in_channels, (1, kernel_size_small), (0, pad_s))

        # 3. å„å‘åŒæ€§åˆ†æ”¯ (æ•è·å±€éƒ¨ç»†èŠ‚)
        self.local_3x3 = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.GELU()
        )
        self.local_5x5 = DWConv(in_channels, 3, padding=2, dilation=2)

        # 4. é™ç»´è®¡ç®—ç“¶é¢ˆ (é™ä½ FLOPs å¹¶å®ç°é€šé“æ³¨æ„åŠ›å‰ç½®)
        mid_channels = max(in_channels * 6 // reduction, 16)
        self.branch_weight = nn.Sequential(
            nn.Conv2d(in_channels * 6, mid_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.GELU(),
            nn.Conv2d(mid_channels, in_channels * 6, kernel_size=1, bias=False)
        )

        # 5. è·¨ä¸­å¿ƒé£æ ¼è°ƒåˆ¶æ¨¡å— (CCSM)
        self.style_fc = nn.Sequential(
            nn.Conv2d(in_channels * 2, in_channels, 1), 
            nn.GELU(),
            nn.Conv2d(in_channels, in_channels * 2, 1)  
        )

        self.proj_out = nn.Conv2d(in_channels, in_channels, 1, bias=False)

    def forward(self, x):
        shortcut = x
        x = self.proj_in(x)

        x_oriented = self.pre_orient(x)

        lh = self.strip_h_large(x_oriented)
        lw = self.strip_w_large(x_oriented)
        sh = self.strip_h_small(x_oriented)
        sw = self.strip_w_small(x_oriented)
        loc3 = self.local_3x3(x)
        loc5 = self.local_5x5(x)

        branches = [lh, lw, sh, sw, loc3, loc5]

        # ==========================================
        # ä¼˜åŒ– 2ï¼šåŸºäºå…¨å±€ä¸Šä¸‹æ–‡çš„è½»é‡åŒ–ç«äº‰æ€§é—¨æ§ (SKNet Style)
        # ==========================================
        stacked = torch.stack(branches, dim=1) # [B, 6, C, H, W]
        
        # ğŸ”¥ ä¿®å¤ç‚¹ï¼šåœ¨è¿™é‡Œæå‰æå–æ‰€æœ‰ç»´åº¦ä¿¡æ¯
        B, num_branches, C, H, W = stacked.shape
        
        # æå–å„ä¸ªåˆ†æ”¯çš„å…¨å±€ç»Ÿè®¡é‡ (å°ºå¯¸å˜åŒ–: [B, 6, C, H, W] -> [B, 6*C, 1, 1])
        global_info = stacked.mean(dim=(3, 4)).view(B, num_branches * C, 1, 1) 
        
        # è®¡ç®—åˆ†æ”¯æƒé‡
        weight = self.branch_weight(global_info) # [B, 6*C, 1, 1]
        weight = weight.view(B, num_branches, C, 1, 1) # reshape
        weight = F.softmax(weight, dim=1)        # è½¯ç«äº‰
        
        # åŠ¨æ€èåˆç‰¹å¾
        out = (weight * stacked).sum(dim=1)      # [B, C, H, W]

        # ==========================================
        # ä¼˜åŒ– 1ï¼šä¸¥è°¨çš„è·¨ä¸­å¿ƒé£æ ¼è°ƒåˆ¶ (CCSM - True Domain Alignment)
        # ==========================================
        out_flat = out.view(B, C, -1)
        
        # æå–å‡å€¼å’Œæ ‡å‡†å·® (å°ºå¯¸ä¸º [B, C, 1])
        feat_mean = out_flat.mean(dim=2, keepdim=True) 
        var = out_flat.var(dim=2, keepdim=True, unbiased=False)
        feat_std = torch.sqrt(var + 1e-5)              
        
        # æ‹¼æ¥å¹¶æ‰©å±•ä¸º [B, 2C, 1, 1] ä¾›å…¨è¿æ¥å±‚ä½¿ç”¨
        style_feat = torch.cat([feat_mean, feat_std], dim=1).unsqueeze(-1) 
        
        gamma_beta = self.style_fc(style_feat)
        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)
        gamma = 2.0 * torch.sigmoid(gamma) 
        
        # ğŸ”¥ å…ˆè¿›è¡Œç‰¹å¾çš„å»é£æ ¼åŒ– (Instance Normalization)ï¼Œå†è¿›è¡Œé‡æ ‡å®š
        # å°† [B, C, 1] unsqueeze(-1) å˜ä¸º [B, C, 1, 1] ä»¥åŒ¹é… out çš„ç»´åº¦è¿›è¡Œå¹¿æ’­
        out_norm = (out - feat_mean.unsqueeze(-1)) / (feat_std.unsqueeze(-1) + 1e-5)
        out = gamma * out_norm + beta
        
        out = self.proj_out(out)

        return shortcut + out