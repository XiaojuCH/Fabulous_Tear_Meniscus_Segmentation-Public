import os
import argparse
import json
import torch
import numpy as np
import cv2
from torch.utils.data import DataLoader
from tqdm import tqdm
from monai.metrics import compute_hausdorff_distance, compute_dice
import matplotlib.pyplot as plt

from dataset import TearDataset
from model import ST_SAM

# =================é…ç½®=================
IMG_SIZE = 1024
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def compute_metric(pred, gt):
    """
    pred, gt: [1, 1, H, W] tensor, binary (0/1)
    """
    # ã€å…³é”®ä¿®æ”¹ã€‘å¼ºåˆ¶è½¬åˆ° CPU è®¡ç®—ï¼Œé¿å¼€ MONAI çš„ CuPy å…¼å®¹æ€§ Bug
    pred = pred.cpu()
    gt = gt.cpu()

    # 1. Dice
    dice = compute_dice(y_pred=pred, y=gt, include_background=False).item()
    
    # 2. HD95 (Hausdorff Distance 95%)
    # æ³¨æ„ï¼šMONAI çš„ HD95 è¾“å…¥å¿…é¡»æ˜¯åŒ…å«è‡³å°‘ä¸€ä¸ªå‰æ™¯åƒç´ çš„ Batch
    if gt.sum() > 0 and pred.sum() > 0:
        hd95 = compute_hausdorff_distance(y_pred=pred, y=gt, include_background=False, percentile=95).item()
    else:
        # å¦‚æœ GT æœ‰ä¸œè¥¿ä½†é¢„æµ‹å…¨é»‘ï¼Œæˆ–è€…åä¹‹ï¼Œç»™ä¸€ä¸ªæƒ©ç½šå€¼ (æ¯”å¦‚ 100ä¸ªåƒç´ è·ç¦»)
        hd95 = 100.0 if gt.sum() > 0 else 0.0
        
    return dice, hd95

def visualize(image, gt, pred, save_path):
    """
    image: [3, H, W] tensor
    gt, pred: [1, H, W] tensor
    """
    # è½¬ numpy
    img_np = image.permute(1, 2, 0).cpu().numpy()
    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min()) # å½’ä¸€åŒ–åˆ° 0-1 ç”¨äºæ˜¾ç¤º
    
    gt_np = gt.squeeze().cpu().numpy()
    pred_np = pred.squeeze().cpu().numpy()
    
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.imshow(img_np)
    plt.title("Input Image")
    plt.axis('off')
    
    plt.subplot(1, 3, 2)
    plt.imshow(img_np)
    plt.imshow(gt_np, alpha=0.5, cmap='Greens') # GT ç”¨ç»¿è‰²è¦†ç›–
    plt.title("Ground Truth (Green)")
    plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.imshow(img_np)
    plt.imshow(pred_np, alpha=0.5, cmap='Reds') # Pred ç”¨çº¢è‰²è¦†ç›–
    plt.title("Prediction (Red)")
    plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

def main(fold):
    print(f"ğŸ” å¼€å§‹è¯„ä¼° Fold {fold}...")
    
    # 1. å‡†å¤‡ç›®å½•
    vis_dir = f"./visualization/fold_{fold}"
    os.makedirs(vis_dir, exist_ok=True)
    
    # 2. åŠ è½½æ•°æ®
    split_path = f"./data_splits/fold_{fold}.json"
    with open(split_path, 'r') as f:
        split_data = json.load(f)
    
    val_dataset = TearDataset(split_data['val'], mode='val', img_size=IMG_SIZE)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)
    
    # 3. åŠ è½½æ¨¡å‹
    model = ST_SAM(checkpoint_path="./checkpoints/sam2_hiera_large.pt").to(DEVICE)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    ckpt_path = f"./checkpoints/fold_{fold}/best_model.pth"
    if not os.path.exists(ckpt_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ {ckpt_path}")
        return

    # æ³¨æ„ï¼šè®­ç»ƒæ—¶ä¿å­˜çš„æ˜¯ model.module.state_dict() (å› ä¸ºç”¨äº† DDP)
    # åŠ è½½æ—¶å¦‚æœä¸æ˜¯ DDP ç¯å¢ƒï¼Œéœ€è¦å»æ‰ key é‡Œçš„ "module." å‰ç¼€
    state_dict = torch.load(ckpt_path, map_location=DEVICE)
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith("module."):
            new_state_dict[k[7:]] = v
        else:
            new_state_dict[k] = v
            
    model.load_state_dict(new_state_dict)
    model.eval()
    
    # 4. æ¨ç†å¾ªç¯
    total_dice = []
    total_hd95 = []
    
    # è¿™é‡Œçš„ box ä¾ç„¶ä½¿ç”¨ Dataset é‡ŒåŸºäº GT ç”Ÿæˆçš„
    # åœ¨è®ºæ–‡ä¸­ï¼Œè¿™å« "Oracle Box" å®éªŒï¼Œè¯æ˜åˆ†å‰²èƒ½åŠ›çš„ä¸Šé™
    # å®é™…ä¸´åºŠåº”ç”¨æˆ‘ä»¬ä¼šè¡¥ä¸€ä¸ªæ£€æµ‹ç½‘ç»œï¼Œä½†ç°åœ¨å…ˆçœ‹åˆ†å‰²ç½‘ç»œæœ¬èº«å¼ºä¸å¼º
    
    with torch.no_grad():
        for i, batch in tqdm(enumerate(val_loader), total=len(val_loader)):
            image = batch['image'].to(DEVICE)
            label = batch['label'].to(DEVICE)
            box = batch['box'].to(DEVICE)
            img_id = batch['id'][0] # è·å–æ–‡ä»¶å/ID
            
            # Forward
            pred_logits = model(image, box)
            pred_probs = torch.sigmoid(pred_logits)
            pred_mask = (pred_probs > 0.5).float()
            
            # Metrics
            dice, hd95 = compute_metric(pred_mask, label)
            total_dice.append(dice)
            total_hd95.append(hd95)
            
            # Visualization (æ¯ 50 å¼ å­˜ä¸€å¼ ï¼Œæˆ–è€…å­˜ metrics æ¯”è¾ƒå·®çš„)
            if i % 50 == 0:
                save_path = os.path.join(vis_dir, f"{img_id}_D{dice:.3f}_H{hd95:.1f}.png")
                visualize(image[0], label[0], pred_mask[0], save_path)
                
    # 5. æ±‡æŠ¥ç»“æœ
    mean_dice = np.mean(total_dice)
    mean_hd95 = np.mean(total_hd95)
    
    print("\n" + "="*30)
    print(f"ğŸ“Š Fold {fold} Final Results:")
    print(f"   Dice: {mean_dice:.4f}")
    print(f"   HD95: {mean_hd95:.4f}") # å…³æ³¨è¿™ä¸ªï¼Swin-UNet æ›¾é«˜è¾¾ 72
    print("="*30)
    print(f"ğŸ–¼ï¸ å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³: {vis_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--fold", type=int, default=0)
    args = parser.parse_args()
    main(args.fold)