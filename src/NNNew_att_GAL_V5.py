import torch
import torch.nn as nn
import torch.nn.functional as F

class DWConv(nn.Module):
    def __init__(self, dim, kernel_size, padding, dilation=1):
        super().__init__()
        self.dw = nn.Conv2d(
            dim, dim, 
            kernel_size=kernel_size, 
            padding=padding, 
            dilation=dilation, 
            groups=dim, 
            bias=False
        )
        self.bn = nn.BatchNorm2d(dim)
        # å¯¹é½ SAM 2 åŸç”Ÿæ¿€æ´»å‡½æ•°ï¼Œä¿è¯ç‰¹å¾æµå½¢å¹³æ»‘
        self.act = nn.SiLU()

    def forward(self, x):
        return self.act(self.bn(self.dw(x)))

# ğŸš€ V5 æ€æ‰‹é” 1ï¼šæå…¶è½»é‡çš„é€šé“æçº¯æ³¨æ„åŠ› (æŠ‘åˆ¶åå…‰å™ªå£°)
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=4):
        super().__init__()
        mid_channels = max(channels // reduction, 16)
        self.attn = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, mid_channels, 1, bias=False),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=False),
            nn.Sigmoid()
        )
    def forward(self, x):
        return x * self.attn(x)

class GAL_Adapter(nn.Module):
    def __init__(self, in_channels, kernel_size_large=23, kernel_size_small=7, reduction=4):
        super().__init__()
        self.proj_in = nn.Conv2d(in_channels, in_channels, 1, bias=False)

        self.pre_orient = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.SiLU()
        )

        pad_l = (kernel_size_large - 1) // 2
        pad_s = (kernel_size_small - 1) // 2
        self.strip_h_large = DWConv(in_channels, (kernel_size_large, 1), (pad_l, 0))
        self.strip_w_large = DWConv(in_channels, (1, kernel_size_large), (0, pad_l))
        self.strip_h_small = DWConv(in_channels, (kernel_size_small, 1), (pad_s, 0))
        self.strip_w_small = DWConv(in_channels, (1, kernel_size_small), (0, pad_s))

        self.local_3x3 = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.SiLU()
        )
        self.local_5x5 = DWConv(in_channels, 3, padding=2, dilation=2)

        mid_channels = max(in_channels * 6 // reduction, 16)
        
        # åšå®ˆ V1 æœ€ç¨³å¦¥çš„ 1x1 åƒç´ çº§ç©ºé—´èåˆ
        self.branch_weight = nn.Sequential(
            nn.Conv2d(in_channels * 6, mid_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.SiLU(),
            nn.Conv2d(mid_channels, in_channels * 6, kernel_size=1, bias=False)
        )

        # ğŸš€ æ¥å…¥ SE é€šé“æçº¯æ¨¡å—
        self.se_block = SEBlock(in_channels, reduction=reduction)

        # ğŸš€ V5 æ€æ‰‹é” 2ï¼šTriple-Stat CCSM 
        # è¾“å…¥å˜ä¸º 3 ä»½ç»Ÿè®¡é‡ (Mean, Std, Max)ï¼Œç»´åº¦ä¸º in_channels * 3
        self.style_fc = nn.Sequential(
            nn.Conv2d(in_channels * 3, in_channels, 1), 
            nn.SiLU(),
            nn.Conv2d(in_channels, in_channels * 2, 1)  
        )

        self.proj_out = nn.Conv2d(in_channels, in_channels, 1, bias=False)
        
        # ç¨³å®šåˆå§‹åŒ–çš„ç¼©æ”¾å› å­ï¼Œé˜²å´©ç¥å™¨
        self.adapter_scale = nn.Parameter(torch.ones(1) * 0.01)

    def forward(self, x):
        shortcut = x
        x = self.proj_in(x)

        x_oriented = self.pre_orient(x)

        lh = self.strip_h_large(x_oriented)
        lw = self.strip_w_large(x_oriented)
        sh = self.strip_h_small(x_oriented)
        sw = self.strip_w_small(x_oriented)
        loc3 = self.local_3x3(x)
        loc5 = self.local_5x5(x)

        branches = [lh, lw, sh, sw, loc3, loc5]

        # ç©ºé—´èåˆé˜¶æ®µ (ç»ä¸æ”¹å˜åŸç‰ˆæ‹“æ‰‘è¿è´¯æ€§)
        cat_feat = torch.cat(branches, dim=1)
        weight = self.branch_weight(cat_feat)

        B, C6, H, W = weight.shape
        C = C6 // 6
        weight = weight.view(B, 6, C, H, W)
        weight = F.softmax(weight, dim=1) 

        stacked = torch.stack(branches, dim=1)
        out = (weight * stacked).sum(dim=1) 

        # ==========================================
        # ğŸš€ V5 é˜¶æ®µ 1ï¼šå…¨å±€é€šé“æçº¯ (æ¶ˆç­åå…‰å™ªå£°é€šé“)
        # ==========================================
        out = self.se_block(out)

        # ==========================================
        # ğŸš€ V5 é˜¶æ®µ 2ï¼šä¸‰å…ƒæç«¯ç»Ÿè®¡ CCSM (Mean+Std+Max)
        # ==========================================
        b, c, h, w = out.shape
        out_flat = out.view(b, c, -1)
        
        # 1. å‡å€¼ (æ•´ä½“èƒŒæ™¯äº®åº¦é”šç‚¹)
        feat_mean = out_flat.mean(dim=2, keepdim=True).unsqueeze(-1) # [B, C, 1, 1]
        
        # 2. ğŸš€ æ–°å¢ï¼šæœ€å¤§å€¼ (æ™®æ‹‰è¥¿å¤šåå…‰ç¯å¤©èŠ±æ¿é”šç‚¹)
        feat_max, _ = out_flat.max(dim=2, keepdim=True)
        feat_max = feat_max.unsqueeze(-1) # [B, C, 1, 1]
        
        # 3. æ–¹å·® (å…¨å±€å¯¹æ¯”åº¦)
        var = out_flat.var(dim=2, keepdim=True, unbiased=False)
        feat_std = torch.sqrt(var + 1e-5).unsqueeze(-1) # [B, C, 1, 1]
        
        # å°†ä¸‰è€…æ‹¼æ¥ï¼Œèµ‹äºˆç½‘ç»œä¸Šå¸è§†è§’çš„å¼ºåº¦åˆ†å¸ƒä¿¡æ¯
        style_feat = torch.cat([feat_mean, feat_std, feat_max], dim=1) # [B, 3C, 1, 1]
        
        gamma_beta = self.style_fc(style_feat)
        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)
        gamma = 2.0 * torch.sigmoid(gamma) 
        
        out = gamma * out + beta
        out = self.proj_out(out)

        # åŠ¨æ€æ®‹å·®è¿æ¥
        return shortcut + out * self.adapter_scale